---
title: 'От косинусного сходства к «энергии» смыслов: как исследование Tencent CALM меняет правила игры в ИИ-подборе'
date: '2026-01-25'
description: 'В статье анализируется исследование лаборатории Tencent — архитектура CALM (Continuous Autoregressive Language Models) — и её потенциал для трансформации процессов HR-теха. Мы рассматриваем ограничения традиционного косинусного сходства при сопоставлении навыков и предлагаем альтернативные методы: использование энергетической оценки (Energy Score), создание устойчивого латентного пространства через вариационную регуляризацию и повышение семантической пропускной способности векторов. Статья описывает путь от «хрупких» эмбеддингов к высокоточным системам автоматизированного матчинга талантов.'
tags: ['AI', 'HRTech', 'Tencent', 'CALM', 'NLP', 'Matching']
authors: ['Iconicompany Team']
language: 'ru'
---

# От косинусного сходства к «энергии» смыслов: как исследование Tencent CALM меняет правила игры в ИИ-подборе

В мире HR-технологий и автоматизированного подбора персонала векторное представление навыков (embeddings) стало «золотым стандартом». Мы в **Iconicompany** постоянно ищем способы сделать сопоставление резюме и вакансий точнее. Традиционно для этого используется косинусное сходство, но достаточно ли его?

Недавнее исследование лаборатории WeChat AI (Tencent) под названием **CALM (Continuous Autoregressive Language Models)** предлагает радикально новый взгляд на работу с векторами, который может навсегда изменить наш подход к матчингу.

### Проблема «хрупких» векторов

Большинство современных моделей извлекают навыки в виде векторов, которые затем сравниваются в пространстве. Однако авторы CALM указывают на критическую проблему: стандартные методы обучения создают **«хрупкие» представления (brittle representations)**.

В таком пространстве даже небольшое изменение в формулировке навыка (например, «Python разработчик» vs «Программист Python») может привести к тому, что векторы окажутся неоправданно далеко друг от друга. Косинусное сходство в этом случае выдает низкий процент соответствия, хотя семантически это одно и то же.

### Чему нас учит CALM: 3 метода улучшения матчинга

Исследование Tencent предлагает несколько инструментов, которые мы можем адаптировать для улучшения качества сопоставления:

#### 1. Переход к Energy Score (Энергетической оценке)

Вместо того чтобы просто измерять угол между двумя векторами (косинусное сходство), CALM использует **Energy Score** — метрику, которая оценивает соответствие на основе расстояний между выборками.

* 
**Почему это лучше:** Энергетическая оценка учитывает не только близость векторов, но и их «разнообразие» (diversity term). Это позволяет точнее оценивать не просто один навык, а целый *набор* компетенций в резюме относительно вакансии, избегая «схлопывания» смыслов.
#### 2. Создание «гладкого» латентного пространства

Чтобы векторы были устойчивы к шуму и разным формулировкам, авторы применяют **вариационную регуляризацию (Variational Regularization)**.

* 
**Как это применить:** Мы можем обучать наши модели извлечения навыков так, чтобы они сопоставляли тексту не точку в пространстве, а небольшое распределение (Gaussian posterior). Использование метода **KL-clipping** (отсечение KL-дивергенции) гарантирует, что каждая размерность вектора несет полезную информацию и не превращается в «белый шум».



#### 3. Избыточность через Vector Dropout

Интересный инсайт из статьи: использование **Dropout** для векторов во время обучения заставляет модель учить избыточные (redundant) представления.

* Это делает систему матчинга невероятно устойчивой. Даже если часть информации в резюме представлена нечетко, модель все равно сможет восстановить истинный смысл и выдать корректный процент соответствия.



### Наш взгляд: Можно ли улучшить модель?

Безусловно. Подход CALM доказывает, что будущее не за увеличением количества параметров, а за увеличением **«семантической пропускной способности» (semantic bandwidth)** каждого шага.

Для задач Iconicompany это означает переход от простого сравнения «слово-в-слово» к анализу целых «смысловых блоков» (chunks). Автоэнкодер CALM сжимает группу токенов в один вектор с точностью восстановления более 99.9%. Это позволяет нам кодировать сложные профессиональные требования в единые, плотные векторы, которые сравниваются гораздо эффективнее, чем среднее арифметическое отдельных слов.

### Итог

Косинусное сходство — это отличный старт, но для высокоточного матчинга талантов его уже недостаточно. Инновации Tencent в области непрерывных моделей дают нам математический фундамент для создания более «умных» и устойчивых систем. Мы в **Iconicompany** уже начали экспериментировать с внедрением энергетических метрик и регуляризации пространства, чтобы наши клиенты находили идеальных кандидатов еще быстрее.

*Хотите узнать больше о том, как мы внедряем передовые исследования в практику? Подписывайтесь на наши обновления!*



*Основано на материалах: "Continuous Autoregressive Language Models" (Shao et al., 2025).* 

Статья: https://arxiv.org/abs/2510.27688
Код: https://github.com/shaochenze/calm
