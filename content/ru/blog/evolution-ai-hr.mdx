---
title: 'Сравнительный анализ алгоритмов матчинга в самообучающемся контуре'
date: '2025-11-27'
description: 'В статье рассматривается подход к построению автономной системы подбора персонала, способной к непрерывному самообучению без участия человека-разметчика. Предложена архитектура, где различные алгоритмы ранжирования (векторный поиск на базе fine-tuned embeddings, MLP, Batch-нейросети) конкурируют за максимизацию метрики качества. В качестве эталона ("Ground Truth") и генератора обучающих пар используется Большая Языковая Модель (LLM), оценивающая семантическое соответствие пар «специалист-вакансия». Приводятся результаты сравнительного анализа корреляции предсказаний алгоритмов с оценками LLM, демонстрирующие превосходство дообученных эмбеддингов над сложными нейросетевыми классификаторами в условиях ограниченной выборки.'
tags: ['AI', 'HR', 'LLM', 'AutoML']
authors: ['slavb18']
language: 'ru'
---

В сфере HR-Tech проблема автоматического сопоставления резюме (CV) и вакансий (JD) остается одной из ключевых. Традиционные рекомендательные системы требуют огромного количества поведенческих данных (кликов, приглашений, наймов), которые в HR накапливаются медленно. Более того, качество этих данных часто страдает от субъективности рекрутеров.

Мы предлагаем подход **«Self-Improving Matching Loop»** — замкнутый контур, где:

1. Система генерирует пары кандидатов.
2. LLM выступает в роли «Идеального Рекрутера», размечая данные.
3. Алгоритмы обучаются на этих данных и конкурируют между собой.
4. Лучший алгоритм автоматически выводится в продакшн.

Цель данной работы — проанализировать эффективность различных архитектур (Vector Search vs MLP vs Batch) внутри этого контура и определить оптимальную стратегию отсечения нерелевантных кандидатов.

## Конкурирующие архитектуры

В эксперименте участвовали три подхода к оценке схожести:

1. **MatchedCosine (Fine-tuned Embeddings):** Использование косинусного сходства между векторами текста, полученными с помощью языковой модели, дообученной на доменных данных.
2. **MatchedMlp (Multi-Layer Perceptron):** Полносвязная нейронная сеть, принимающая на вход конкатенированные признаки пары и предсказывающая вероятность матча.
3. **MatchedBatch:** Пакетное сопоставление через нейронную сеть, оптимизирующее функцию потерь сразу для группы кандидатов.

## LLM как арбитр (Ground Truth)

Вместо ручной разметки использовалась оценка соответствия (matched), полученная от LLM (Gemini). Модель анализировала текст вакансии и профиль специалиста, выдавая оценку релевантности от 0 до 1. Это позволило быстро получить плотную матрицу оценок для N=2867 пар, обеспечив высокую скорость итераций R&D.

## Результаты эксперимента

Был проведен корреляционный анализ Спирмена между предсказаниями алгоритмов и эталонной оценкой (matched).

Результаты показали значительный разрыв в качестве работы алгоритмов:

| Алгоритм | Spearman Correlation | Размер выборки (n) | Интерпретация |
| --- | --- | --- | --- |
| **MatchedCosine** | **0.4392** | 2867 | **Умеренная связь.** Лучший показатель. |
| MatchedBatch | 0.1928 | 1749 | Слабая связь. Высокая зашумленность. |
| MatchedMlp | 0.1180 | 2867 | Связь отсутствует. Уровень случайного шума. |

**Наблюдение:**
Векторный поиск (MatchedCosine) оказался единственным методом, демонстрирующим статистически
значимую связь с целевой метрикой. Методы MatchedMlp и MatchedBatch показали низкую
способность к обобщению на данной итерации обучения.

## Архитектура самообучения

Полученные результаты подтверждают гипотезу о том, что **fine-tuned embeddings** являются наиболее робастным решением для старта системы ("холодный старт").

Однако, ценность системы не в победе одного алгоритма, а в **автоматическом выявлении победителя**. Разработанный конвейер работает по принципу эволюционного отбора:

1. **Генерация:** Система непрерывно создает новые версии алгоритмов.
2. **Валидация:** LLM автоматически оценивает их качество на отложенной выборке (как показано в эксперименте).
3. **Ротация:** Если MatchedMlp_v2 покажет корреляцию 0.5 против 0.44 у Cosine, трафик автоматически переключится на него.

Текущая неудача MLP и Batch в эксперименте — это не провал архитектуры, а сигнал автоматическому конвейеру о необходимости изменения гиперпараметров обучения (например, изменения функции потерь или добавления майнинга негативных примеров) без вмешательства инженеров.

Мы продемонстрировали работающий прототип самообучающейся системы матчинга. На текущем этапе развития системы:

1. **Рекомендовано использование MatchedCosine** как основного алгоритма ранжирования.
2. **Установлен порог отсечения**, обеспечивающий оптимальный баланс Precision/Recall.
3. **Исключены MatchedBatch и MatchedMlp** из контура принятия решений до момента их дообучения, так как они вносят шум.

Дальнейшее развитие системы предполагает использование полученных "чистых" данных
(отфильтрованных через Cosine и подтвержденных LLM) для переобучения (distillation) более сложных моделей MLP, замыкая цикл улучшения качества.

